data = [
    ("00000000", "06-26-2011", 200, "Exercise", "GymnasticsPro", "cash"),
    ("00000001", "05-26-2011", 300, "Exercise", "Weightlifting", "credit"),
    ("00000002", "06-01-2011", 100, "Exercise", "GymnasticsPro", "cash"),
    ("00000003", "06-05-2011", 100, "Gymnastics", "Rings", "credit"),
    ("00000004", "12-17-2011", 300, "Team Sports", "Field", "paytm"),
    ("00000005", "02-14-2011", 200, "Gymnastics", "", "cash")
]

# Create an RDD from the data
rdd = spark.sparkContext.parallelize(data)

# Convert RDD to DataFrame using toDF() and specify column names
columns = ["txnno", "txndate", "amount", "category", "product", "spendby"]
csvdf = rdd.toDF(columns)
print()
print("===== raw dataframe ===")
print()

csvdf.show()

print()
print("===== Category not equal to Exercise ===")
print()

notfilter = csvdf.filter(" category != 'Exercise' ")
notfilter.show()

print()
print("===== category=Exercise and spendby=cash ===")
print()

notfil1 = csvdf.filter(" category='Exercise' and spendby !='cash' ")
notfil1.show()