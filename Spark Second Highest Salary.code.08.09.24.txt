Spark Second Highest Salary


from pyspark.sql.functions import  *


data = [("DEPT3", 500),
        ("DEPT3", 200),
        ("DEPT1", 1000),
        ("DEPT1", 700),
        ("DEPT1", 500),
        ("DEPT2", 400),
        ("DEPT2", 200)]
columns = ["dept", "salary"]

# Create DataFrame
df = spark.createDataFrame(data, columns)

df.show()

from pyspark.sql.window import  Window

## Defined My Window

deptwindow = Window.partitionBy("dept").orderBy(col("salary").desc())

## Applying window with Dense Rank

dfrank = df.withColumn("drank", dense_rank().over(deptwindow))

dfrank.show()

filterdf= dfrank.filter("drank=2")

filterdf.show()

finaldf = filterdf.drop("drank")

finaldf.show()